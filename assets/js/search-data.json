{
  
    
        "post0": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master- badges: true- comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://stanlee321.github.io/stan-blog/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "Jurados Electorales de  PDF a CSV",
            "content": "Parser de PDF a CSV de los jurados electorales. . El objetivo de este notebook es obtener un CSV que pueda luego ser analizado y explorado. Este notebook muestra los pasos necesarios para parsear el archivo jurados.pdf a CSV. . Se tubo un problema a la hora de extraer con regular expressions los Doc. de Identidad con valores alfanumericos. Se deja como trabajo restanto, limpiar la columna respectiva y adyasentes a estos valores. . Setup . Se siguen los ejemplos de https://nbviewer.jupyter.org/github/chezou/tabula-py/blob/master/examples/tabula_example.ipynb . %pip install tabula-py . Collecting tabula-py Downloading tabula_py-2.2.0-py3-none-any.whl (11.7 MB) |████████████████████████████████| 11.7 MB 1.1 MB/s eta 0:00:01 |██████████████████▊ | 6.8 MB 1.9 MB/s eta 0:00:03 |███████████████████ | 6.9 MB 1.9 MB/s eta 0:00:03 |███████████████████▎ | 7.0 MB 1.9 MB/s eta 0:00:03 Requirement already satisfied: pandas&gt;=0.25.3 in /home/stanlee321/anaconda3/envs/scraping_p37/lib/python3.7/site-packages (from tabula-py) (1.0.5) Requirement already satisfied: numpy in /home/stanlee321/anaconda3/envs/scraping_p37/lib/python3.7/site-packages (from tabula-py) (1.19.1) Collecting distro Downloading distro-1.5.0-py2.py3-none-any.whl (18 kB) Requirement already satisfied: python-dateutil&gt;=2.6.1 in /home/stanlee321/anaconda3/envs/scraping_p37/lib/python3.7/site-packages (from pandas&gt;=0.25.3-&gt;tabula-py) (2.8.1) Requirement already satisfied: pytz&gt;=2017.2 in /home/stanlee321/anaconda3/envs/scraping_p37/lib/python3.7/site-packages (from pandas&gt;=0.25.3-&gt;tabula-py) (2020.1) Requirement already satisfied: six&gt;=1.5 in /home/stanlee321/anaconda3/envs/scraping_p37/lib/python3.7/site-packages (from python-dateutil&gt;=2.6.1-&gt;pandas&gt;=0.25.3-&gt;tabula-py) (1.15.0) Installing collected packages: distro, tabula-py Successfully installed distro-1.5.0 tabula-py-2.2.0 Note: you may need to restart the kernel to use updated packages. . Some imports . from tqdm import tqdm import pandas as pd from tabula import read_pdf . Read PDF file . Se crea una lista de dataframes que contienen la informacion de cada pagina del pdf. . # Read the pdf as a list of dataframes dfs = read_pdf(&quot;jurados.pdf&quot;, pages=&quot;all&quot;, guess=False) print(len(dfs)) dfs[0].head(n=10) . 3072 . Unnamed: 0 Unnamed: 1 ESTADO PLURINACIONAL DE BOLIVIA Unnamed: 2 Unnamed: 3 Unnamed: 4 Unnamed: 5 . 0 NaN | NaN | ÓRGANO ELECTORAL PLURINACIONAL | NaN | NaN | NaN | NaN | . 1 NaN | NaN | Tribunal Electoral Departamental de La Paz | NaN | NaN | NaN | NaN | . 2 NaN | NaN | Elecciones Generales 2020 | NaN | NaN | NaN | NaN | . 3 NaN | NaN | 18 de Octubre de 2020 | NaN | NaN | NaN | NaN | . 4 País: | Bolivia | LISTADO DE JURADOS ELECTORALES | NaN | NaN | NaN | NaN | . 5 N° | Apellidos y Nombres | Doc. de Identidad Municipio | Recinto | NaN | Mesa | NaN | . 6 1 | ABALO LUQUE JUDITH NANCY | I 9102281 El Alto | Col. Rotary Chuquiago Marca | NaN | NaN | 1.0 | . 7 2 | ABALOS CHOQUE MANCY | I 4960747 El Alto | Unidad Educativa Juan Capriles | NaN | NaN | 1.0 | . 8 3 | ABALOS QUISPE MARUJA MERCEDES | I 4943746 El Alto | Col. Tunari | NaN | NaN | 1.0 | . 9 4 | ABARIOJO YUCO MARCO ANTONIO | I 1939274 Nuestra Señora de La Paz | Col. Cristo Rey | NaN | NaN | 1.0 | . Processing . Se crea una copia de la lista de dataframes para no volver a cargar el archivo pdf. . dfs_dev = dfs.copy() . Se procedio a probar diferentes paginas (su valor en la lista es su valor como pagina en el pdf). En este caso el 3041 . df = dfs_dev[3041].iloc[5:] # Rename columns df.columns = df.iloc[0] # Use as dataframe the ramaining data. df = df[1:] df.tail() . 5 N° Apellidos y Nombres Doc. de Identidad Municipio Recinto Mesa NaN . 20 54.753 | ZAVALA ESPINOZA CLAUDIA ANTONIETA | I 4790366 Nuestra Señora de La Paz | Escuela Rosemari de Barrientos | 46.0 | . 21 54.754 | ZAVALA HUMEREZ FEDERICO ERNESTO | I 4311981 Nuestra Señora de La Paz | Esc. San Martin | 34.0 | . 22 54.755 | ZAVALA JIMENEZ MARIO ALBERTO | I 8312089 El Alto | Colegio Walter Alpire 2do Patio | 14.0 | . 23 54.756 | ZAVALA JIMENEZ PAOLA ANDREA | I 10920426 El Alto | Colegio Walter Alpire 1er Patio | 28.0 | . 24 Fecha: | 18/09/2020 | NaN | Página: 3.042 de 3.072 | NaN | . Se puede ver que hay valores de &quot;fecha -- - - - - &quot; al final del dataframe. Posteriormente se limpiara estos valores. . . if &quot;Recinto Mesa&quot; in list(df.columns): df.rename(columns={&quot;Recinto Mesa&quot;: &quot;Recinto&quot; }, inplace=True) . df.head() . 5 N° Apellidos y Nombres Doc. de Identidad Municipio Recinto NaN . 6 54.739 | ZARSURI LUNA LIMBER | I 7015364 Cairoma | U.E. Araca Torre Pampa | 3.0 | . 7 54.740 | ZARSURI RIASA JULIA | I 6805130 Inquisivi | Escuela Eliodoro Camacho | 5.0 | . 8 54.741 | ZARSURI SALAZAR CINTHYA STEPHANIE | I 6894259 Nuestra Señora de La Paz | Escuela Superior de Formación de Maestros Simo... | 15.0 | . 9 54.742 | ZARSURI TARQUI GABRIEL FRANZ | I 4376305 Ixiamas | Esc. German Busch | 15.0 | . 10 54.743 | ZARSURI TINTAYA EDITH | I 9090775 El Alto | U.E. Iberdrola | 1.0 | . Se procede a eliminar los N ultimos elementos de la tabla, el ultimo elemento que corresponde a la fecha se lo señala con un 1. . df.drop(df.tail(1).index,inplace=True) . df.tail() . 5 N° Apellidos y Nombres Doc. de Identidad Municipio Recinto Mesa NaN . 19 54.374 | ZAMBRANA FLORES BORIS PABLO | I 2622984 Nuestra Señora de La Paz | Unidad Educativa Los Pinos | 26.0 | . 20 54.375 | ZAMBRANA FLORES LUIS MIGUEL | I 6827045 Nuestra Señora de La Paz | Esc. Jose Santos | 21.0 | . 21 54.376 | ZAMBRANA FUENTES JOEL OMAR | I 9947828 Viacha | Esc. San Luis | 22.0 | . 22 54.377 | ZAMBRANA GALARZA QUISPE PRIMITIVA | I 6130700 El Alto | Colegio 6 de Junio | 26.0 | . 23 54.378 | ZAMBRANA GARCIA OSVALDO ENRIQUE | I 5501507 Nuestra Señora de La Paz | Escuela Pedro Poveda | 17.0 | . REGEX . Se utiliza regular expresion para separar los valores de la columna &quot;Doc. de Identidad Municipio&quot;. . Es aqui donde se tubo problmeas para parsear los valores alfanumericos que podria tener un Documento de Identidad. . df[&quot;Doc. de Identidad Municipio&quot;].str.split(r&quot; b( d+) b([^ w-])&quot;, expand=True) . 0 1 2 3 . 6 I | 6824163 | | Achocalla | . 7 I | 8461434 | | Nuestra Señora de La Paz | . 8 I | 5497883 | | Nuestra Señora de La Paz | . 9 I | 6936357 | | Apolo | . 10 I | 7313138 | | El Alto | . 11 I | 6794431 | | Nuestra Señora de La Paz | . 12 I | 1883348 | | El Alto | . 13 I | 4891939 | | Nuestra Señora de La Paz | . 14 I | 13927008 | | El Alto | . 15 I | 12670368 | | El Alto | . 16 I | 4901684 | | Nuestra Señora de La Paz | . 17 I | 8320777 | | Nuestra Señora de La Paz | . 18 I | 6935873 | | Nuestra Señora de La Paz | . 19 I | 2622984 | | Nuestra Señora de La Paz | . 20 I | 6827045 | | Nuestra Señora de La Paz | . 21 I | 9947828 | | Viacha | . 22 I | 6130700 | | El Alto | . 23 I | 5501507 | | Nuestra Señora de La Paz | . Se crean 4 columnas adicionales para alojar los valores que el REGEX encontro . df[[&quot;PREFIX - Doc. de Identidad&quot;, &quot;Doc. de Identidad&quot;, &quot;unnamed:0&quot;, &quot;Municipio&quot;]] = df[&quot;Doc. de Identidad Municipio&quot;].str.split(r&quot; b( d+) b([^ w-])&quot;, expand=True) . Revisar cuantos valores nan se tienen en los nombres de las columnas . print(len(df.columns)) for c in df.columns: print(type(c), c) . 9 &lt;class &#39;str&#39;&gt; N° &lt;class &#39;str&#39;&gt; Apellidos y Nombres &lt;class &#39;str&#39;&gt; Doc. de Identidad Municipio &lt;class &#39;str&#39;&gt; Recinto Mesa &lt;class &#39;numpy.float64&#39;&gt; nan &lt;class &#39;str&#39;&gt; PREFIX - Doc. de Identidad &lt;class &#39;str&#39;&gt; Doc. de Identidad &lt;class &#39;str&#39;&gt; unnamed:0 &lt;class &#39;str&#39;&gt; Municipio . Limpiar los valores nan de los nombres de las columnas . Se renombrar los valores de los nombres de las columnas que tubieran valores nan con placeholders denominados unnamed:X donde X es un indice que se autoincrementa por el numero de valores nan presentes en las columnas. . # List hte actual column names df_names_to_fix = pd.Series(df.columns) # Create a new list with fixed column names df_names_fixed = df_names_to_fix.fillna(&#39;unnamed:&#39; + (df_names_to_fix.groupby(df_names_to_fix.isnull()).cumcount() + 1).astype(str)) # Set the new column names to the test dataframe df.columns = df_names_fixed . df.head() . 5 N° Apellidos y Nombres Doc. de Identidad Municipio Recinto Mesa unnamed:1 PREFIX - Doc. de Identidad Doc. de Identidad unnamed:0 Municipio . 6 54.361 | ZAMBRANA CHEJO INES AMPARO | I 6824163 Achocalla | U. E. Marquirivi | 14.0 | I | 6824163 | | Achocalla | . 7 54.362 | ZAMBRANA CHOQUE JOSE ALFREDO | I 8461434 Nuestra Señora de La Paz | Escuela Superior de Formación de Maestros Simo... | 15.0 | I | 8461434 | | Nuestra Señora de La Paz | . 8 54.363 | ZAMBRANA CLAUDIA PAMELA | I 5497883 Nuestra Señora de La Paz | Esc. Sagrado Corazon De Jesus | 35.0 | I | 5497883 | | Nuestra Señora de La Paz | . 9 54.364 | ZAMBRANA COLQUE JHANETH CATALINA | I 6936357 Apolo | U. E. Machua | 1.0 | I | 6936357 | | Apolo | . 10 54.365 | ZAMBRANA COLQUE VANIA | I 7313138 El Alto | Col. Santa Maria De Los Angeles | 35.0 | I | 7313138 | | El Alto | . print(len(df.columns)) for c in df.columns: print(type(c), c) . 5 &lt;class &#39;str&#39;&gt; N° &lt;class &#39;str&#39;&gt; Apellidos y Nombres &lt;class &#39;str&#39;&gt; Doc. de Identidad Municipio &lt;class &#39;str&#39;&gt; Recinto &lt;class &#39;numpy.float64&#39;&gt; nan . df[&quot;unnamed:0&quot;].unique() . array([&#39; &#39;], dtype=object) . Reemplazar los valores de Mesa por los extraidos . Como ya se tiene extraido el valor de mesa en una columna auxiliar , en este caso &quot;unnamed:1&quot;, se procede a coloar su valor en su columna respectiva. . df[&quot;Mesa&quot;] = df[&quot;unnamed:1&quot;] . Se quitan las columnas auxiliares. . df.drop(columns=[&quot;Doc. de Identidad Municipio&quot;, &quot;unnamed:0&quot;], inplace=True) . df.head() . 5 N° Apellidos y Nombres Recinto Mesa unnamed:1 PREFIX - Doc. de Identidad Doc. de Identidad Municipio . 6 54.361 | ZAMBRANA CHEJO INES AMPARO | U. E. Marquirivi | 14.0 | I | 6824163 | Achocalla | . 7 54.362 | ZAMBRANA CHOQUE JOSE ALFREDO | Escuela Superior de Formación de Maestros Simo... | 15.0 | I | 8461434 | Nuestra Señora de La Paz | . 8 54.363 | ZAMBRANA CLAUDIA PAMELA | Esc. Sagrado Corazon De Jesus | 35.0 | I | 5497883 | Nuestra Señora de La Paz | . 9 54.364 | ZAMBRANA COLQUE JHANETH CATALINA | U. E. Machua | 1.0 | I | 6936357 | Apolo | . 10 54.365 | ZAMBRANA COLQUE VANIA | Col. Santa Maria De Los Angeles | 35.0 | I | 7313138 | El Alto | . Crear el pipeline para todos las p&#225;ginas. . Con las herramientas creadas, se procede a crear un pipeline para extrar todos todas las tablas de todas las paginas. . Crear funciones auxiliares . def fix_nan_column_names(df_column_names): &quot;&quot;&quot; Create a clean column names, where nan are replace by unnamed:X value, where X is an index for each nan value found. &quot;&quot;&quot; # List hte actual column names df_names_to_fix = pd.Series(df_column_names) # Create a new list with fixed column names df_names_fixed = df_names_to_fix.fillna(&#39;unnamed:&#39; + (df_names_to_fix.groupby(df_names_to_fix.isnull()).cumcount() + 1).astype(str)) return df_names_fixed def clean_dataframe(df_input): &quot;&quot;&quot; Function para limpiar el dataframe que proviene de read_pdf . Se procesa los nombres de las columnas segun las variaciones de tamaño y nombres que pueda tener el dataframe input PARAMS: - df_input: Dataframe que proviene del parser read_pdf RETURNS: - df : Dataframe que fue procesador y limpiado. &quot;&quot;&quot; # Create a copy to work on of the dataframe df = df_input.copy() # Remove datetime row df.drop(df.tail(1).index,inplace=True) # drop last n rows # Delete the first 5 rows df = df.iloc[5:] # Set the column name to the first element of this new rows df.columns = df.iloc[0] # Start the rows from the next one element # since we choose 0 as the new column names df = df[1:] # If recinto mesa is in column names, change his name. if &quot;Recinto Mesa&quot; in list(df.columns): df.rename(columns={&quot;Recinto Mesa&quot;: &quot;Recinto&quot; }, inplace=True) # REGEX part # Create New Columns spliting the nested one &quot;Doc. de Identidad Municipio&quot; using regex df[[&quot;PREFIX - Doc. de Identidad&quot;, &quot;Doc. de Identidad&quot;, &quot;unnamed:0&quot;, &quot;Municipio&quot;]] = df[&quot;Doc. de Identidad Municipio&quot;].str.split(r&quot; b( d+) b([^ w-])&quot;, expand=True) # List The actual column names new_colum_names = fix_nan_column_names(df.columns) # First kind of Variation for column names if (len(new_colum_names) == 11) or (len(new_colum_names) == 10): # Set the new column names to the test dataframe df.columns = new_colum_names try: # Set the value from this &quot;Mesa_Aux&quot; to the &quot;Mesa&quot; column df[&quot;Mesa&quot;] = df[&quot;unnamed:2&quot;] df.drop(columns=[&quot;Doc. de Identidad Municipio&quot;, &quot;unnamed:2&quot;, &quot;unnamed:0&quot;, &quot;unnamed:1&quot;], inplace=True) except Exception as e: # Set the value from this &quot;Mesa_Aux&quot; to the &quot;Mesa&quot; column df[&quot;Mesa&quot;] = df[&quot;unnamed:1&quot;] df.drop(columns=[&quot;Doc. de Identidad Municipio&quot;, &quot;unnamed:0&quot;, &quot;unnamed:1&quot;], inplace=True) finally: return df # Second Kind of variation for column names if len ( new_colum_names) == 12: # Set the new column names to the test dataframe df.columns = new_colum_names # Drop Unused column names df.drop(columns=[&quot;Doc. de Identidad Municipio&quot;, &quot;unnamed:3&quot;, &quot;unnamed:2&quot;, &quot;unnamed:0&quot;, &quot;unnamed:1&quot;], inplace=True) return df # Third Kind of Variation for column names if len ( new_colum_names) == 9: df.columns = new_colum_names try: df[&quot;Mesa&quot;] = df[&quot;unnamed:1&quot;] df.drop(columns=[&quot;Doc. de Identidad Municipio&quot;, &quot;unnamed:1&quot;, &quot;unnamed:0&quot;], inplace=True) except: df.drop(columns=[&quot;Doc. de Identidad Municipio&quot;, &quot;unnamed:0&quot;], inplace=True) finally: return df # If no match for new_colum_names # print len for debug later print(len ( new_colum_names)) return None . df_clean = clean_dataframe(dfs[3041]) df_clean.tail() . 5 N° Apellidos y Nombres Recinto PREFIX - Doc. de Identidad Doc. de Identidad Municipio Mesa . 19 54.752 | ZARZURI TENORIO DIEGO HERLAND | Colegio Mariscal Santa Cruz | I | 9173050 | Achacachi | 21.0 | . 20 54.753 | ZAVALA ESPINOZA CLAUDIA ANTONIETA | Escuela Rosemari de Barrientos | I | 4790366 | Nuestra Señora de La Paz | 46.0 | . 21 54.754 | ZAVALA HUMEREZ FEDERICO ERNESTO | Esc. San Martin | I | 4311981 | Nuestra Señora de La Paz | 34.0 | . 22 54.755 | ZAVALA JIMENEZ MARIO ALBERTO | Colegio Walter Alpire 2do Patio | I | 8312089 | El Alto | 14.0 | . 23 54.756 | ZAVALA JIMENEZ PAOLA ANDREA | Colegio Walter Alpire 1er Patio | I | 10920426 | El Alto | 28.0 | . Crear funcion para el pipeline . def create_clean_dfs(dfs): &quot;&quot;&quot; Funcion para procesar y limpiear una lista de dataframes. PARAMS: dfs: List of Dataframes RETURNS: - status : dict , donde cada uno de los KEYS, corresponde los nombres &quot;FAIL&quot; u &quot;GOOD&quot; y los VALUES una lista de dataframes que fueron procesados correctamente y los que fallaron. &quot;&quot;&quot; status = { &quot;TO_FIX_DATAFRAME&quot;: [], &quot;DFS_CLEAN&quot;:[] } # Iterate over the list of dataframes for df_raw in tqdm(dfs): # Use the function for clean the dataframe df_clean = clean_dataframe(df_raw) # if dataframe is NOne if df_clean is None: # Appen this to the list of fails status[&quot;TO_FIX_DATAFRAME&quot;].append(df_clean) # Break the loop for debug what just happened break else: # Procede to append the clean dataframe to the # DFS_CLEAN dataframe list status[&quot;DFS_CLEAN&quot;].append(df_clean) print(f&quot;&quot;&quot; FAIL: {len(status[&quot;TO_FIX_DATAFRAME&quot;])}, GOOD: {len(status[&quot;DFS_CLEAN&quot;])} &quot;&quot;&quot;) return status . status = create_clean_dfs(dfs_dev) . 100%|██████████| 3072/3072 [00:30&lt;00:00, 99.70it/s] . FAIL: 0, GOOD: 3072 . . Concatenate Dataframe . Ya que se tiene una lista de dataframes uniformes, se los pasara a concatenar en un solo dataframe. . dfs_clean = pd.concat(status[&quot;DFS_CLEAN&quot;]) # Check Shape print(dfs_clean.shape) # Check Head dfs_clean.head() . (55284, 7) . N° Apellidos y Nombres Recinto Mesa PREFIX - Doc. de Identidad Doc. de Identidad Municipio . 6 1 | ABALO LUQUE JUDITH NANCY | Col. Rotary Chuquiago Marca | 1 | I | 9102281 | El Alto | . 7 2 | ABALOS CHOQUE MANCY | Unidad Educativa Juan Capriles | 1 | I | 4960747 | El Alto | . 8 3 | ABALOS QUISPE MARUJA MERCEDES | Col. Tunari | 1 | I | 4943746 | El Alto | . 9 4 | ABARIOJO YUCO MARCO ANTONIO | Col. Cristo Rey | 1 | I | 1939274 | Nuestra Señora de La Paz | . 10 5 | ABASTO ARANIBAR MAURICIO WILSON | Colegio Dora Schmidt | 1 | I | 9196248 | Nuestra Señora de La Paz | . dfs_clean.tail() . N° Apellidos y Nombres Recinto Mesa PREFIX - Doc. de Identidad Doc. de Identidad Municipio . 7 55.280 | ZURITA VALLEJOS GROBER | U. E. 16 de Julio de Mapiri | 15 | I | 8824037 | Mapiri | . 8 55.281 | ZURITA VILLCA JOB MARCELO | Escuela Puerto Perez | 6 | I | 9239461 | Puerto Pérez | . 9 55.282 | ZURITA ZABALETA JEANNETH MARY | Colegio Don Bosco | 44 | I | 4289623 | El Alto | . 10 55.283 | ZURITA ZELADA ADALID | Liceo Bolivia | 7 | I | 3768774 | Nuestra Señora de La Paz | . 11 55.284 | ZUZAÑO FLORES MARCELO | Esc. Mscal. Antonio Jose De Sucre | 4 | I | 10064472 | Nuestra Señora de La Paz | . Save to CSV . dfs_clean.to_csv(&quot;JURADOS_CLEAN.csv&quot;, index=False) .",
            "url": "https://stanlee321.github.io/stan-blog/jupyter/2020/02/20/extract-jurados.html",
            "relUrl": "/jupyter/2020/02/20/extract-jurados.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://stanlee321.github.io/stan-blog/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://stanlee321.github.io/stan-blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://stanlee321.github.io/stan-blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}